{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKEGJhmprkzC",
        "outputId": "f89b8113-3994-4dbe-c4a5-1f8dbf58cdfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in 'class': ['f' 'r' 's' 'i' 'a']\n",
            "Accuracy: 0.8764491337762147\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.85      0.86      6613\n",
            "         1.0       0.89      0.90      0.89      8741\n",
            "\n",
            "    accuracy                           0.88     15354\n",
            "   macro avg       0.87      0.87      0.87     15354\n",
            "weighted avg       0.88      0.88      0.88     15354\n",
            "\n",
            "Predicted Classes for New Data: [0. 0.]\n",
            "Models saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\systempc\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '../data/instagram_profile_final.csv'  # Update this with your file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the unique values in the 'class' column\n",
        "print(\"Unique values in 'class':\", data['class'].unique())\n",
        "\n",
        "# Map class labels to binary (1: real, 0: fake)\n",
        "class_mapping = {'r': 1, 'f': 0}  # Map 'r' (real) to 1 and 'f' (fake) to 0\n",
        "data['class'] = data['class'].map(class_mapping)\n",
        "\n",
        "# Drop rows with NaN values in 'class' (unmapped or missing)\n",
        "data = data.dropna(subset=['class'])\n",
        "\n",
        "# Check for and handle missing values in features\n",
        "data = data.dropna()  # Drop rows with missing values in features\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('class', axis=1)\n",
        "y = data['class']\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Decision Tree model\n",
        "dt_model_final = DecisionTreeClassifier(random_state=42)\n",
        "dt_model_final.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred = dt_model_final.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Prediction Function\n",
        "def predict_new_data(new_data):\n",
        "    \"\"\"\n",
        "    Predict the class for new data points.\n",
        "\n",
        "    Args:\n",
        "        new_data (list or 2D array): New data points to predict.\n",
        "\n",
        "    Returns:\n",
        "        list: Predicted classes (1 for real, 0 for fake).\n",
        "    \"\"\"\n",
        "    # Ensure new data has the same number of features as training data\n",
        "    if len(new_data[0]) != X.shape[1]:\n",
        "        raise ValueError(f\"New data must have {X.shape[1]} features, but got {len(new_data[0])} features.\")\n",
        "\n",
        "    # Ensure new data is scaled\n",
        "    new_data_scaled = scaler.transform(new_data)\n",
        "    predictions = dt_model_final.predict(new_data_scaled)\n",
        "    return predictions\n",
        "\n",
        "# Example: Predict on new data\n",
        "# Replace the values below with actual feature values (matching the feature count in training data)\n",
        "example_data = [\n",
        "    [0.5, 0.8, -0.3, 1.2, 0.7, 0.0, 0.1, 0.2, -0.1, 0.4, 0.5, 1.1, 0.6, 0.3, -0.2, 0.8, 0.9],  # Example data point 1 with 17 features\n",
        "    [1.0, -0.5, 0.4, 0.6, -1.2, 0.8, 0.3, 0.4, 0.1, 0.9, 1.0, -0.4, 0.7, 0.2, 0.5, 0.9, -0.1]   # Example data point 2 with 17 features\n",
        "]\n",
        "\n",
        "# example_data = [\n",
        "#     # Example 1: Features likely representing a \"real\" account\n",
        "#     [1.0, 0.9, 0.7, 0.6, 1.2, 0.8, 0.6, -0.5, 0.3, 1.0, 0.9, 1.3, 1.2, 0.7, 0.1, 0.8, 0.9],  # High positive values in multiple features\n",
        "\n",
        "#     # Example 2: Features likely representing a \"real\" account\n",
        "#     [0.9, 1.1, 0.6, 0.5, 1.0, 0.7, 0.5, -0.4, 0.4, 0.8, 1.0, 1.1, 0.9, 0.6, 0.2, 0.7, 1.0],  # More balanced, but with a slight positive trend\n",
        "# ]\n",
        "\n",
        "predicted_classes = predict_new_data(example_data)\n",
        "print(\"Predicted Classes for New Data:\", predicted_classes)\n",
        "\n",
        "\n",
        "with open(\"../models/decision_tree_model_final.pkl\", \"wb\") as dt_file:\n",
        "    pickle.dump(dt_model_final, dt_file)\n",
        "\n",
        "print(\"Models saved successfully!\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
